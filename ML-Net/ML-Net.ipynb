{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML-Net for silency prediction\n",
        "##### Mount drive\n",
        "In testing enviroment learning data were stored on Google drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Import needed libraries\n",
        "To make things work ensure that you have this libraries installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0vumoX4mPDg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras import initializers, regularizers, constraints\n",
        "import keras.backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Configuration parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH = 10 # batch size\n",
        "\n",
        "IMG_HEIGHT = 480 # input image width\n",
        "IMG_WIDTH = 640 # input image height\n",
        "\n",
        "MAP_HEIGHT = int(math.ceil(IMG_HEIGHT / 8)) # extracted feature map height\n",
        "MAP_WIDTH = int(math.ceil(IMG_WIDTH / 8)) # extracted feature map width \n",
        "\n",
        "EPOCHS = 40 # number of epochs\n",
        "\n",
        "TRAIN_IMG_PATH = \"/content/drive/MyDrive/salicon/images/train\" # path to training images\n",
        "VAL_IMG_PATH = \"/content/drive/MyDrive/salicon/images/val\" # path to validation images\n",
        "TRAIN_MAP_PATH = \"/content/drive/MyDrive/salicon/maps/train\" # path to training maps\n",
        "VAL_MAP_PATH = \"/content/drive/MyDrive/salicon/maps/val\" # path to validation maps\n",
        "\n",
        "TRAIN_SIZE = 1000 # number of training samples\n",
        "VAL_SIZE = 500 # number of validation samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Eltwise product layer\n",
        "Custom layer responsible for learning prior bias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EltWiseProduct(Layer):\n",
        "    def __init__(self, downsampling_factor=10, init='glorot_uniform', activation='linear',\n",
        "                 weights=None, W_regularizer=None, activity_regularizer=None,\n",
        "                 W_constraint=None, input_dim=None, **kwargs):\n",
        "        self.downsampling_factor = downsampling_factor\n",
        "        self.init = initializers.get(init)\n",
        "        self.activation = activation\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.input_dim = input_dim\n",
        "\n",
        "        if self.input_dim:\n",
        "            kwargs['input_shape'] = (self.input_dim,)\n",
        "\n",
        "        self.input_spec = InputSpec(ndim=4)\n",
        "        super(EltWiseProduct, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W_shape = (MAP_HEIGHT, MAP_WIDTH, 1)   # Adjusted weight shape for broadcasting\n",
        "        self.W = self.add_weight(shape=self.W_shape,\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None,) + input_shape[1:])\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        output = x * tf.expand_dims(1 + self.W, 0)\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'downsampling_factor': self.downsampling_factor,\n",
        "            'init': initializers.serialize(self.init),\n",
        "            'activation': self.activation,\n",
        "            'W_regularizer': regularizers.serialize(self.W_regularizer),\n",
        "            'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "            'W_constraint': constraints.serialize(self.W_constraint),\n",
        "            'input_dim': self.input_dim\n",
        "        }\n",
        "        base_config = super(EltWiseProduct, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pre-trained feature extraction network "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_YpeC4axEZc",
        "outputId": "04aef9e8-006e-439e-8c00-58bab970d919"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "vgg19 = tf.keras.applications.vgg19.VGG19(input_shape=(480, 640, 3), include_top=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Actual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vswgdogmc9I",
        "outputId": "5ec5a6c7-4939-4030-8281-5f806d14f3b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"mlnet-vgg19\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)        [(None, 480, 640, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " sequential (Sequential)     (None, 120, 160, 256)        2325568   ['input_2[0][0]']             \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2  (None, 60, 80, 256)          0         ['sequential[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " sequential_1 (Sequential)   (None, 60, 80, 512)          8259584   ['max_pooling2d[0][0]']       \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPoolin  (None, 60, 80, 512)          0         ['sequential_1[0][0]']        \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " sequential_2 (Sequential)   (None, 60, 80, 512)          7079424   ['max_pooling2d_1[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 60, 80, 512)          2359808   ['sequential_2[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 60, 80, 1280)         0         ['max_pooling2d[0][0]',       \n",
            "                                                                     'max_pooling2d_1[0][0]',     \n",
            "                                                                     'conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " dropout (Dropout)           (None, 60, 80, 1280)         0         ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 60, 80, 64)           737344    ['dropout[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 60, 80, 1)            65        ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " elt_wise_product (EltWiseP  (None, 60, 80, 1)            4800      ['conv2d_2[0][0]']            \n",
            " roduct)                                                                                          \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 60, 80, 1)            0         ['elt_wise_product[0][0]']    \n",
            "                                                                                                  \n",
            " resizing (Resizing)         (None, 480, 640, 1)          0         ['activation[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 20766593 (79.22 MB)\n",
            "Trainable params: 20766593 (79.22 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = tf.keras.Input(shape=(480, 640, 3))\n",
        "\n",
        "feature_extraction = tf.keras.Sequential(layers=vgg19.layers[:11])(input)\n",
        "conv3_pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding=\"same\")(feature_extraction)\n",
        "feature_extraction_1 = tf.keras.Sequential(layers=vgg19.layers[12:16])(conv3_pool)\n",
        "conv4_pool = tf.keras.layers.MaxPooling2D((2, 2), strides=(1, 1), padding=\"same\")(feature_extraction_1)\n",
        "more_features = tf.keras.Sequential(layers=vgg19.layers[17:20])(conv4_pool)\n",
        "conv5_4 = tf.keras.layers.Conv2D(512, 3, weights=vgg19.layers[20].get_weights(), activation='relu', padding='same')(more_features)\n",
        "\n",
        "concatenated = tf.keras.layers.concatenate([conv3_pool, conv4_pool, conv5_4], axis=-1)\n",
        "dropout = tf.keras.layers.Dropout(0.5)(concatenated)\n",
        "\n",
        "int_conv = tf.keras.layers.Conv2D(64, 3, kernel_initializer='glorot_normal', activation='relu', padding='same')(dropout)\n",
        "pre_final_conv = tf.keras.layers.Conv2D(1, 1, kernel_initializer='glorot_normal', activation='relu')(int_conv)\n",
        "\n",
        "downsampling_factor_net = 8\n",
        "downsampling_factor_product = 10\n",
        "rows_elt = math.ceil(IMG_HEIGHT / downsampling_factor_net) // downsampling_factor_product\n",
        "cols_elt = math.ceil(IMG_WIDTH / downsampling_factor_net) // downsampling_factor_product\n",
        "eltprod = EltWiseProduct(init='zero', W_regularizer=tf.keras.regularizers.L2(1/(rows_elt*cols_elt)))(pre_final_conv)\n",
        "\n",
        "pre_output = tf.keras.layers.Activation('relu')(eltprod)\n",
        "output = tf.keras.layers.Resizing(IMG_HEIGHT, IMG_WIDTH, interpolation='bicubic')(pre_output)\n",
        "\n",
        "better_model = tf.keras.Model(inputs=input, outputs=output, name=\"mlnet-vgg19\")\n",
        "\n",
        "better_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Custom loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l67geYrBsZIc"
      },
      "outputs": [],
      "source": [
        "def loss(y_true, y_pred):\n",
        "  max_y = K.max(K.max(y_pred, axis=1), axis=1)  # Adjust axis values\n",
        "  max_y = K.repeat_elements(K.expand_dims(K.repeat_elements(K.expand_dims(max_y, axis=-1), IMG_HEIGHT, axis=-1)), IMG_WIDTH, axis=-1)\n",
        "  return K.mean(K.square((y_pred / max_y) - y_true) / (1.1 - y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Compiling model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sgd = tf.keras.optimizers.experimental.SGD(learning_rate=1e-3, momentum=0.9, weight_decay=0.0005, nesterov=True)\n",
        "better_model.compile(optimizer=sgd, loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q45NQ17KsXic"
      },
      "outputs": [],
      "source": [
        "class CustomDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, data, labels, batch_size, size):\n",
        "      datas = [f for f in os.listdir(data)]\n",
        "      labeles = [f for f in os.listdir(labels)]\n",
        "      datas.sort()\n",
        "      labeles.sort()\n",
        "      self.images = [data + \"/\" + f for f in datas[:size]]\n",
        "      self.maps = [labels + \"/\" + f for f in labeles[:size]]\n",
        "\n",
        "      self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.images) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "        x = []\n",
        "        y = []\n",
        "        for f in self.images[start:end]:\n",
        "          image = cv2.imread(f)\n",
        "          image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "          image = tf.keras.applications.vgg16.preprocess_input(image)\n",
        "          x.append(image)\n",
        "\n",
        "        for f in self.maps[start:end]:\n",
        "          image = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "          y.append(image.astype('float32') / 255)\n",
        "\n",
        "        # Implement any data preprocessing here if needed\n",
        "        return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxB1GEB-y7aW"
      },
      "outputs": [],
      "source": [
        "train_generator = CustomDataGenerator(TRAIN_IMG_PATH, TRAIN_MAP_PATH, BATCH, TRAIN_SIZE)\n",
        "validation_generator = CustomDataGenerator(VAL_IMG_PATH, VAL_MAP_PATH, BATCH, VAL_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Learning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Wvf6QUybxL",
        "outputId": "48dfe8d4-5e47-43b0-aafa-3495f4632c9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0551\n",
            "Epoch 1: val_loss improved from inf to 0.05152, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-01-0.05.hdf5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 766s 7s/step - loss: 0.0551 - val_loss: 0.0515\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0490\n",
            "Epoch 2: val_loss improved from 0.05152 to 0.04609, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-02-0.05.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0490 - val_loss: 0.0461\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0465\n",
            "Epoch 3: val_loss improved from 0.04609 to 0.04469, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-03-0.04.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0465 - val_loss: 0.0447\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0446\n",
            "Epoch 4: val_loss improved from 0.04469 to 0.04191, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-04-0.04.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0446 - val_loss: 0.0419\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0429\n",
            "Epoch 5: val_loss improved from 0.04191 to 0.04039, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-05-0.04.hdf5\n",
            "100/100 [==============================] - 231s 2s/step - loss: 0.0429 - val_loss: 0.0404\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0418\n",
            "Epoch 6: val_loss improved from 0.04039 to 0.03899, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-06-0.04.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0418 - val_loss: 0.0390\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0406\n",
            "Epoch 7: val_loss improved from 0.03899 to 0.03787, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-07-0.04.hdf5\n",
            "100/100 [==============================] - 229s 2s/step - loss: 0.0406 - val_loss: 0.0379\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0397\n",
            "Epoch 8: val_loss did not improve from 0.03787\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0397 - val_loss: 0.0380\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0389\n",
            "Epoch 9: val_loss improved from 0.03787 to 0.03639, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-09-0.04.hdf5\n",
            "100/100 [==============================] - 216s 2s/step - loss: 0.0389 - val_loss: 0.0364\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0381\n",
            "Epoch 10: val_loss improved from 0.03639 to 0.03587, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-10-0.04.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0381 - val_loss: 0.0359\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0375\n",
            "Epoch 11: val_loss improved from 0.03587 to 0.03550, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-11-0.04.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0375 - val_loss: 0.0355\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0369\n",
            "Epoch 12: val_loss improved from 0.03550 to 0.03541, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-12-0.04.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0369 - val_loss: 0.0354\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0364\n",
            "Epoch 13: val_loss improved from 0.03541 to 0.03486, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-13-0.03.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0364 - val_loss: 0.0349\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0360\n",
            "Epoch 14: val_loss improved from 0.03486 to 0.03451, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-14-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0360 - val_loss: 0.0345\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0355\n",
            "Epoch 15: val_loss improved from 0.03451 to 0.03414, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-15-0.03.hdf5\n",
            "100/100 [==============================] - 215s 2s/step - loss: 0.0355 - val_loss: 0.0341\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0351\n",
            "Epoch 16: val_loss improved from 0.03414 to 0.03386, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-16-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0351 - val_loss: 0.0339\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0347\n",
            "Epoch 17: val_loss improved from 0.03386 to 0.03376, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-17-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0347 - val_loss: 0.0338\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0343\n",
            "Epoch 18: val_loss improved from 0.03376 to 0.03337, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-18-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0343 - val_loss: 0.0334\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0341\n",
            "Epoch 19: val_loss improved from 0.03337 to 0.03323, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-19-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0341 - val_loss: 0.0332\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0337\n",
            "Epoch 20: val_loss did not improve from 0.03323\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0337 - val_loss: 0.0333\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0335\n",
            "Epoch 21: val_loss improved from 0.03323 to 0.03317, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-21-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0335 - val_loss: 0.0332\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0333\n",
            "Epoch 22: val_loss improved from 0.03317 to 0.03295, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-22-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0333 - val_loss: 0.0329\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0331\n",
            "Epoch 23: val_loss improved from 0.03295 to 0.03280, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-23-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0331 - val_loss: 0.0328\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0327\n",
            "Epoch 24: val_loss did not improve from 0.03280\n",
            "100/100 [==============================] - 213s 2s/step - loss: 0.0327 - val_loss: 0.0329\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0325\n",
            "Epoch 25: val_loss improved from 0.03280 to 0.03247, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-25-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0325 - val_loss: 0.0325\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0324\n",
            "Epoch 26: val_loss did not improve from 0.03247\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0324 - val_loss: 0.0326\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0323\n",
            "Epoch 27: val_loss improved from 0.03247 to 0.03238, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-27-0.03.hdf5\n",
            "100/100 [==============================] - 219s 2s/step - loss: 0.0323 - val_loss: 0.0324\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0320\n",
            "Epoch 28: val_loss improved from 0.03238 to 0.03233, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-28-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0320 - val_loss: 0.0323\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0317\n",
            "Epoch 29: val_loss improved from 0.03233 to 0.03223, saving model to /content/drive/MyDrive/salicon/mlnet-bigger_prior-29-0.03.hdf5\n",
            "100/100 [==============================] - 214s 2s/step - loss: 0.0317 - val_loss: 0.0322\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.0317\n",
            "Epoch 30: val_loss did not improve from 0.03223\n",
            "100/100 [==============================] - 213s 2s/step - loss: 0.0317 - val_loss: 0.0322\n",
            "Epoch 31/40\n",
            " 39/100 [==========>...................] - ETA: 1:53 - loss: 0.0314"
          ]
        }
      ],
      "source": [
        "better_model.fit(train_generator, epochs=EPOCHS, batch_size=BATCH, validation_data=validation_generator, callbacks=[tf.keras.callbacks.EarlyStopping(patience=5), tf.keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/salicon/mlnet-bigger_prior-{epoch:02d}-{val_loss:.2f}.hdf5',save_best_only=True,verbose=1)])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
